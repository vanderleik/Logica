{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVamos usar o dataset iris, que possui dados de flores para 3 categorias.\\nNosso modelo deverá receber dados das flores e prever a qual das 3 categorias a flor pertence.\\n\\nAqui o dataset:\\nhttps://archive.ics.uci.edu/ml/datasets/Iris\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regressão Logística\n",
    "\"\"\"\n",
    "Vamos usar o dataset iris, que possui dados de flores para 3 categorias.\n",
    "Nosso modelo deverá receber dados das flores e prever a qual das 3 categorias a flor pertence.\n",
    "\n",
    "Aqui o dataset:\n",
    "https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacotes para computação e matemática\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para a função de Ativação Sigmoide\n",
    "# Quando estudamos econometria, especialmente o modelo Logit,\n",
    "# vemos essa função que é capaz de criar aquele gráfico com uma linha tangenciando\n",
    "# o limite inferior, perto de zero, e o limite superior do gráfico, perto de 1, em um\n",
    "# formato de S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoide():\n",
    "    def __call__(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo de Machine Learning - Regressão Logística\n",
    "class RegressaoLogistica():\n",
    "    # Construtor da Classe - define os atributos\n",
    "    def __init__(self, learning_rate = .1, gradient_descent = True):\n",
    "        self.param = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gradient_descent = gradient_descent\n",
    "        self.sigmoid = Sigmoide()\n",
    "    # Inicializa os parâmetros\n",
    "    def _inicializa_parametros(self, X):\n",
    "        n_features = np.shape(X)[1]\n",
    "        limit = 1 / math.sqrt(n_features)\n",
    "        self.param = np.random.uniform(-limit, limit, (n_features,))\n",
    "    # Converte uma matriz x para diagonal a fim de realizar os cálculos\n",
    "    def make_diagonal(x):\n",
    "        m = np.zeros((len(x), len(x)))\n",
    "        for i in range(len(m[0])):\n",
    "            m[i, i] = x[i]\n",
    "        return m\n",
    "    # Função para o treinamento\n",
    "    # Aqui está o coração do algoritmo, suas operações matemáticas\n",
    "    # Usamos o gradiente descendente a fim de encontrar o melhor valor dos\n",
    "    # coeficientes, aquilo que o modelo aprende no treinamento\n",
    "    def treinamento(self, X, y, n_iterations = 4000):\n",
    "        self._inicializa_parametros(X)\n",
    "        for i in range(n_iterations):\n",
    "            y_pred = self.sigmoid(X.dot(self.param))\n",
    "            if self.gradient_descent:\n",
    "                self.param -= self.learning_rate * -(y - y_pred).dot(X)\n",
    "            else:\n",
    "                diag_gradient = make_diagonal(self.sigmoid.gradient(X.dot(self.param)))\n",
    "                self.param = np.linalg.pinv(X.T.dot(diag_gradient).dot(X)).dot(X.T).dot(diag_gradient.dot(X).dot(self.param) + y - y_pred)\n",
    "    # Método para previsão com o modelo\n",
    "    def previsao(self, X):\n",
    "        y_pred = np.round(self.sigmoid(X.dot(self.param))).astype(int)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacotes\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para normalizar os dados\n",
    "def normaliza_dados(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para randomizar os dados\n",
    "def randomiza_dados(X, y, seed=None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a acurácia\n",
    "def calcula_acuracia(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para dividir os dados em treino e teste\n",
    "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n",
    "    if shuffle:\n",
    "        X, y = randomiza_dados(X, y, seed)\n",
    "    split_i = len(y) - int(len(y) // (1 / test_size))\n",
    "    X_train, X_test = X[:split_i], X[split_i:]\n",
    "    y_train, y_test = y[:split_i], y[split_i:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para execução do programa\n",
    "def main():\n",
    "    # Carregar os dados\n",
    "    data = load_iris()\n",
    "    # Normalizar os dados de entrada\n",
    "    X = normaliza_dados(data.data[data.target != 0])\n",
    "    # Carregar os dados de saída\n",
    "    y = data.target[data.target != 0]\n",
    "    y[y == 1] = 0\n",
    "    y[y == 2] = 1\n",
    "    # Dividir os dados em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, seed=1)\n",
    "    # Definir o modelo\n",
    "    modelo = RegressaoLogistica(gradient_descent=True)\n",
    "    # Treinar o algoritmo e criar o modelo\n",
    "    modelo.treinamento(X_train, y_train)\n",
    "    # Usar o modelo treinado para fazer previsões\n",
    "    y_pred = modelo.previsao(X_test)\n",
    "    # Calcular a acurácia comparando valores previstos com valores observados\n",
    "    acuracia = calcula_acuracia(y_test, y_pred)\n",
    "    # Imprime a acurácia do modelo\n",
    "    print (\"Acurácia do Modelo:\", acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Modelo: 0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "# Executa o programa\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
